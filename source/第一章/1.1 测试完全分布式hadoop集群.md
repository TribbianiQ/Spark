# 1.1 测试（启动+关闭）完全分布式hadoop集群

Hadoop集群+Spark集群搭建，前提是要保证Hadoop完全分布式集群的成功搭建哦~

## 1.1.1 启动hadoop集群

开启三台虚拟机，在主节点命令行中输入启动命令，先HDFS后YARN。

### Step 1：启动hadoop集群的HDFS服务进程
```bash
start-dfs.sh
```

正常启动情况：
- 主节点01:starting NameNode、starting DataNode
- 从节点02:starting DataNode、starting SecondaryNameNode
- 从节点03:starting DataNode

### Step 2：启动hadoop集群的YARN服务进程
```bash
start-yarn.sh
```

正常启动情况：
- starting yarn daemons
- 主节点01:starting ResourceManager（资源管理器）、starting NodeManager（节点管理器）
- 从节点02:starting NodeManager
- 从节点03:starting NodeManager

## 1.1.2 使用jps命令查看服务启动情况

在3台机器上分别使用`jps`命令，查看各个节点的服务启动情况

```bash
jps
```
主节点01共有5个进程，从节点02共有4个进程，从节点03共有3个进程（进程缺一不可！少一个就说明整个hadoop集群没有完全启动，否则会导致后期实验无法正常执行。）

![start_state]()

## 1.1.3 关闭hadoop集群

在主节点命令行中输入关闭命令

```bash
stop-dfs.sh
stop-yarn.sh
```
